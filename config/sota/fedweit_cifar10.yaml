# FedWeIT on CIFAR10 - Federated Weighted Inter-client Transfer
# Based on: https://proceedings.mlr.press/v139/yoon21b.html

dataset:
  workload: cifar10
  batch_size: 32
  num_classes: 10

model:
  name: simple_cnn
  num_classes: 10

cl:
  strategy: fedweit
  num_experiences: 5
  split: random

# FedWeIT-specific configurations
fedweit:
  sparsity: 0.5  # Target sparsity for task-adaptive parameters
  l1_lambda: 0.1  # L1 regularization for sparsity
  l2_lambda: 100.0  # Retroactive update regularization

training:
  learning_rate: 0.001
  epochs: 3
  optimizer: adam

server:
  strategy: fedweit  # Use custom FedWeIT server strategy
  num_rounds: 10
  num_clients: 3
  fraction_fit: 1.0
  fraction_eval: 1.0
  min_fit: 3
  min_eval: 3

client:
  num_cpus: 4
  num_gpus: 0.5  # CPU for testing
  epochs: 3
  falloff: 0.0
  exp_epochs: null  # Use server num_rounds instead

wb:
  project: autofl-testing
  name: fedweit_cifar10_simplecnn 